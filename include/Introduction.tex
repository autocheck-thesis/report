\chapter{Introduction}

Today, Computer Science and Engineering students at Chalmers submit their programming assignments to \cite{2019Fire:System} for assessment. Fire has some support for setting up automatic checks to evaluate the submissions, but does not provide any resources or infrastructure to do so. As a consequence many teachers and Teacher assistants end up running submitted code on their personal workstations. This increases both the workload and wait times, since even trivial errors will not be caught until the assignment has been compiled and run manually. Additionally, running arbitrary code on their own computers opens them up to an array of security vulnerabilities. In contrast, an ideal system for automatic checks would be easily configured, run automatically in a sandboxed environment upon submission and provide direct feedback to the student.

For example, in an algorithms course, automatic checks could run a compiler and a test suite on source code that students submit. The submissions could then have test cases which via direct feedback would help the student write a correct solution without teacher feedback.

The goal of this project is to design and build a distributed, scalable and secure infrastructure for running automatic checks, with the intention of lowering manual labor and code duplication. The system will lower the barrier of entry for teachers who want to enable automatic testing and verification for their assignments.

To make the system as widely available as possible, it will be Learning Tools Interoperability (LTI) compatible. LTI is a standard used to connect Learning Management Systems (LMS) with external content and service providers. The system will be tested using the LTI-compatible \cite{2019Canvas}, as Chalmers is currently transitioning to Canvas from their previous legacy system Ping Pong.